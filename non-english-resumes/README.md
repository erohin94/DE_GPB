# Resume Language Filter

Утилита для автоматического исключения резюме на английском языке из профилей кандидатов.

# Описание задачи

При скачивании резюме кандидатов, часть резюме приходит на англиском языке. Необходимо исключить такие резюме.

# Решение

Изначально поиск таких резюме осуществлялся с помощью библиотеки `langdetect`. Но как выяснилось в ходе тестов, библиотека некорректно определяет язык для коротких текстов.
Например слово "Бармен" - библиотека считает что написано не на русском языке.

Было принято решение использовать для поиска регулярки. 
Тоесть скрипт анализирует текстовые поля резюме и подсчитывает количество символов, принадлежащих к кириллическому и латинскому алфавитам. 
Язык определяется по преобладающему алфавиту. Если в тексте больше или равно 80% текста на английском, то считаем что резюме на английском.
Если например в резюме 79% текста на английском и 21% на русском, то резюме считаем русским и такое резюме подходит.

Ноутбук с примером во вложении. В дальнейшем эта функция будет встроена в основной ETL скрипт.

# Логика работы ETL

**Описание процесса фильтрации резюме**

Данный процесс предназначен для формирования и очистки базовой таблицы `search_result_table` в Hadoop, которая содержит только релевантные для дальнейших расчетов идентификаторы резюме. Ключевой задачей является исключение резюме на английском языке для определенных вакансий, не нарушая при этом целостности данных по другим вакансиям, связанным с тем же резюме.

**1. Первоначальное формирование данных**

На основе поисковых шаблонов скачиваются краткие данные о резюме.
Данные сохраняются в оперативной памяти в виде датафрейма `df_resume_list` со следующей структурой:

`resume_id` — уникальный идентификатор резюме.

`owner_id` — идентификатор владельца резюме.

`url` — URL резюме.

`url_w_contacts` — URL для доступа к контактам.

`vacancy_code` — код вакансии, по которой было найдено резюме.

`search_status` — статус поиска.

`area_id` — идентификатор региона.

Данные из `df_resume_list` переносятся в постоянную таблицу `search_result_table` в Hadoop.

**2. Скачивание полных резюме и детектирование языка**

Для каждого `resume_id` из таблицы `search_result_table` отправляются запросы к API для получения полных текстов резюме.

Фильтрация по языку: На этом этапе происходит проверка языка резюме.

Если обнаруживается, что резюме составлено на английском языке, его `resume_id` заносится в специальный список `eng_resume_ids`.

Сохранение в Hadoop. Полные тексты всех резюме (как на русском, так и на английском) сохраняются в соответствующей таблице в Hadoop.

**3. Фильтрация английских резюме для конкретных вакансий**

Цель: Исключить из рабочего датафрейма `df_resume_list` только те записи, где резюме на английском языке соответствует определенным кодам вакансий (1003, 1004, 10012). При этом необходимо сохранить другие вакансии для того же `resume_id`.

Один `resume_id` может быть связан с несколькими `vacancy_code`. Необходимо удалить только нежелательные пары (`resume_id`, `vacancy_code`), а не все упоминания `resume_id`.

Решение:

Создается фильтр `df_eng_filter`, который представляет собой подмножество строк из исходного `df_resume_list`. В этот фильтр попадают строки, где:

`resume_id` находится в списке `eng_resume_ids` (резюме на английском).

`vacancy_code` входит в список запрещенных кодов (1003, 1004, 10012).

Обновляем датафрейм. Из исходного `df_resume_list` вычитаются строки, попавшие в `df_eng_filter`. В результате в обновленном `df_resume_list` остаются:

- Все резюме на русском языке.

- Резюме на английском языке, но с кодами вакансий, не входящими в запрещенный список.

Для `resume_id` с несколькими вакансиями удаляются только запрещенные комбинации. Например, для `resume_id=123` с вакансиями (10012, 1008) будет удалена только строка с `vacancy_code=10012`, а строка с `vacancy_code=1008` останется в датафрейме.

**4. Финализация базовой таблицы**

Делаем очистку (Truncate). Cуществующая таблица `search_result_table` в Hadoop полностью очищается.

В очищенную таблицу загружаются данные из обновленного датафрейма `df_resume_list`.

В результате описанного процесса таблица `search_result_table` в Hadoop содержит только те идентификаторы резюме и коды вакансий, которые прошли фильтрацию и являются релевантными для последующих расчетов. Эта таблица становится основой для всех последующих `JOIN-операций` в ETL-процессах, гарантируя, что в расчеты не попадут некорректные данные (например, резюме на английском языке для вакансий, где это недопустимо), даже если одно резюме было найдено по нескольким разным вакансиям.
